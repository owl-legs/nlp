{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92a4772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5458b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alexrotondo/Documents/nlp'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee84a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Downloads/JEOPARDY_QUESTIONS1.json', 'r') as file:\n",
    "    questions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ede352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'HISTORY',\n",
       " 'air_date': '2004-12-31',\n",
       " 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\",\n",
       " 'value': '$200',\n",
       " 'answer': 'Copernicus',\n",
       " 'round': 'Jeopardy!',\n",
       " 'show_number': '4680'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dae8fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(questions):\n",
    "    processedQuestions = []\n",
    "    for question in questions:\n",
    "        processedQuestions += ['<bos> ' + question['question'].lower()[1:-1] + ' <eos>']\n",
    "    return processedQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec8cbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedQuestions = preprocess(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a617452",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(processedQuestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b92bce68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216930"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "082a7deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos> the city of yuma in this state has a record average of 4,055 hours of sunshine each year <eos>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedQuestions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "348b93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_counts(questions):\n",
    "    tokenCounts = {}\n",
    "    for question in questions:\n",
    "        tokens = question.split(' ')\n",
    "        for token in tokens:\n",
    "            if token in tokenCounts:\n",
    "                tokenCounts[token] += 1\n",
    "            else:\n",
    "                tokenCounts[token] = 1\n",
    "    return tokenCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b088626",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenCounts = get_token_counts(processedQuestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4adbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_grams(n, questions):\n",
    "    ngrams = {}\n",
    "    for question in questions:\n",
    "        tokens = question.split(' ')\n",
    "        grams = [tuple(tokens[i:i+n]) for i in range(len(tokens) - n)]\n",
    "        for gram in grams:\n",
    "            if gram in ngrams:\n",
    "                ngrams[gram] += 1\n",
    "            else:\n",
    "                ngrams[gram] = 1\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6d06cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = get_n_grams(2, processedQuestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f856cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_gram_probabilities(ngrams, tokenCounts):\n",
    "    n = sum(ngrams.values())\n",
    "    for ngram in ngrams:\n",
    "        ngrams[ngram] /= tokenCounts[ngram[0]]\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "644a13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramProbabilities = get_n_gram_probabilities(bigrams, tokenCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3cc4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
